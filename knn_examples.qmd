---
title: "KNN Tidymodels Example"
author: "JMG"
format: 
  html:
    echo: true
    code-fold: false
    toc: true
    self-contained: true
---

```{r}
#| include: false
#| message: false
#| warning: false

library(tidyverse)
library(tidymodels)
library(kableExtra)
library(ggthemes)

tidymodels_prefer()

theme_set(theme_minimal(base_size = 12))
```

## The Data

Throughout this notebook, we will use the `penguins` data set available through the `modeldata` package which gets loaded with the `tidymodels` family of packages. This data set contains information about penguins collected from 3 different species over three different islands. Each row in the data set corresponds to a single penguin for which the species, island, sex, and four physical body measurements are recorded.  

```{r}
#| echo: true
#| code-fold: true
#| label: tbl-pengs-dat
#| tbl-cap: "The first 6 rows of the penguins data set."

penguins %>%
  head(6) %>%
  kable() %>%
  kable_styling() %>%
  scroll_box(width = "100%", height = "200px")
```

There is some missing data in the data set so the first thing we will do is remove any observation with missing data.

```{r}

penguins <- penguins %>%
  drop_na()

```

Now, we are interested in two types of problems:

1. A classification problem where we want to predict the sex of penguins based on physical measurements and perhaps the species and island it was collected from.

2. A regression problem where we want to predict the body mass of penguins based on physical measurements and perhaps the sex and species as well.

For both problems, we will use the nearest neighbors algorithm to make our predictions. Further, we will use the `tidymodels` framework to perform the analysis. This framework is built on top of the `tidyverse` and provides a consistent interface for performing machine learning tasks. Later in the course, we will study the `tidymodels` framework in more detail. For now, we will just use it to perform our analysis.

### EDA

Before getting into an analysis, let's take a look at some exploratory plots of the data. @fig-pengs-plots shows how male and female penguins differ by flipper length and body mass. 

```{r}
#| echo: true
#| code-fold: true
#| label: fig-pengs-plots
#| fig-cap: Plot to see if the flipper length and body mass can distinguish the sex of a penguin. 


penguins %>%
  ggplot(aes(x = flipper_length_mm, y = body_mass_g, color = sex)) +
  geom_point() +
  theme(legend.position = "bottom") + 
  scale_color_colorblind() +
  labs(x = "Flipper Length (mm)", y = "Body Mass (g)")
```


It appears that male penguins tend to be heavier than female penguins but just body mass and flipper length do not clearly separate male and female penguins. Most likely, this is do to the fact that one or more species of penguins are mixed together in this data set.

 @fig-pengs-species reproduces @fig-pengs-plots to show how male and female penguins differ by flipper length and body mass but also incorporates differences across species. 


```{r}
#| echo: true
#| code-fold: true
#| label: fig-pengs-species
#| fig-cap: Plot to see if the flipper length and body mass can distinguish the sex of a penguin where we also take into account difference across species. 

penguins %>%
  ggplot(aes(x = flipper_length_mm, y = body_mass_g, color = species)) +
  geom_point() +
  facet_wrap(~sex) +
  theme(legend.position = "bottom") +
  scale_color_colorblind() +
  labs(x = "Flipper Length (mm)", y = "Body Mass (g)")
```

Now we can see more clearly that within each species, male penguins tend to weigh more and have longer flippers. Furthermore, we can see that a longer flipper tends to correspond with a greater body mass. 



## KNN Examples

For both our classification and regression problems, we will use the `nearest_neighbor()` function from the `tidymodels` package. This function takes a formula as its first argument and a data frame as its second argument. The formula specifies the relationship between the outcome variable and the predictor variables. Before we build our models, we will need to split the data into a training set and a testing set. We will use the `initial_split()` function to do this. This function takes a data frame as its first argument and a proportion as its second argument. The proportion specifies the proportion of the data that should be in the training set. The function returns a list with two elements: `train` and `test`. Each element is a data frame containing the training and testing data, respectively. 

```{r}
#| echo: true

set.seed(1234)

penguins_split <- initial_split(penguins, prop = 0.75, strata = sex)

penguins_train <- training(penguins_split)
penguins_test <- testing(penguins_split)
```




### Classification

Since we are using nearest neighbors, we will need to normalize our quantitative predictors which can be done in a preprocessing step using the function `step_normalize` from the `recipes` package which is loaded with the `tidymodels` family of packages[^1].

[^1]: There are many different types of preprocessing steps that can be performed using the `recipes` package. We will learn more about this package later in the course.

```{r}

peng_sex_rec <- recipe(sex ~ flipper_length_mm + body_mass_g + species,
                       data = penguins_train) %>%
  step_normalize(all_numeric_predictors()) %>%
  step_dummy(all_nominal(),-all_outcomes()) 

  
```

Now, we define out model specification using the `nearest_neighbor()` function from the `parsnip` package which is loaded with the `tidymodels` family of packages. 

```{r}

peng_sex_spec <- nearest_neighbor(neighbors = 5) %>%
  set_engine("kknn") %>%
  set_mode("classification")


```

Now we need to fit our model and use it to make predictions on the test set so we can assess the predictive accuracy of our model. A good way to do this is with a model workflow as follows.

```{r}
peng_sex_wf <- workflow() %>%
  add_recipe(peng_sex_rec) %>%
  add_model(peng_sex_spec)

peng_sex_fit <- fit(peng_sex_wf,penguins_train)
```

Let's examine our results:

```{r}
#| code-fold: true


peng_sex_fit %>%
  predict(penguins_test) %>%
  cbind(penguins_test) %>%
  conf_mat(sex,.pred_class)
```



```{r}
#| code-fold: true


peng_sex_fit %>%
  predict(penguins_test) %>%
  cbind(penguins_test) %>%
  accuracy(sex,.pred_class) %>%
  kable()
```

We can make a plot to show cases where our model made an incorrect prediction.

```{r}
#| code-fold: true

peng_sex_fit %>%
  predict(penguins_test) %>%
  cbind(penguins_test) %>%
  mutate(prediction = ifelse(sex == .pred_class, "Correct", "Incorrect")) %>%
  ggplot(aes(x = flipper_length_mm, y = body_mass_g, color = prediction)) +
  geom_point() +
  facet_wrap(~species) +
  theme(legend.position = "bottom") +
  scale_color_colorblind() +
  labs(x = "Flipper Length (mm)", y = "Body Mass (g)")

```

### Regression

Now, we will use the same approach to build a model to predict the body mass of a penguin. 

```{r}

peng_mass_rec <- recipe(body_mass_g ~ flipper_length_mm + sex + species,
                       data = penguins_train) %>%
  step_normalize(all_numeric_predictors()) %>%
  step_dummy(all_nominal()) 

peng_mass_spec <- nearest_neighbor(neighbors = 5) %>%
  set_engine("kknn") %>%
  set_mode("regression")

peng_mass_wf <- workflow() %>%
  add_recipe(peng_mass_rec) %>%
  add_model(peng_mass_spec)

peng_mass_fit <- fit(peng_mass_wf,penguins_train)

```

Let's examine our results:

```{r}

peng_mass_fit %>%
  predict(penguins_test) %>%
  cbind(penguins_test) %>%
  rmse(body_mass_g,.pred) %>%
  kable()

```

Let's plot our predicted values against the actual values.

```{r}
#| code-fold: true


peng_mass_fit %>%
  predict(penguins_test) %>%
  cbind(penguins_test) %>%
  ggplot(aes(x=body_mass_g, y = .pred)) +
  geom_point(color="darkblue") + 
  geom_abline(linetype="dashed") + 
  labs(x = "Actual Body Mass (g)", y = "Predicted Body Mass (g)")

```

Let's see how the results compare across sex and species.

```{r}
#| code-fold: true


peng_mass_fit %>%
  predict(penguins_test) %>%
  cbind(penguins_test) %>%
  ggplot(aes(x=body_mass_g, y = .pred, color=sex)) +
  geom_point() + 
  geom_abline(linetype="dashed") + 
  facet_wrap(~species) +
  scale_color_colorblind() +
  labs(x = "Actual Body Mass (g)", y = "Predicted Body Mass (g)")
```

### Tuning K

It is possible that the performance of our model depends on our choice of $k$ in the nearest neighbors algorithm. We can try to use the `tune_grid()` function to find the value of $k$ that improves the performance of our model. To do so, we will use a technique known as cross-validation. Later in the course, we will cover cross-validation in detail. For now, we will simply use the `rsample` to build the necessary data for doing the cross-validation.  This package which is loaded with the `tidymodels` family of packages to create a cross-validation object. 


```{r} 

penguins_cv <- vfold_cv(penguins_train,v=10,repeats = 5)

k_grid <- grid_regular(neighbors(), levels = 7)

peng_spec_tune <- nearest_neighbor(neighbors = tune()) %>%
  set_engine("kknn") %>%
  set_mode("classification")

doParallel::registerDoParallel()

set.seed(345)
```

### Classification

```{r}
peng_sex_tune <- tune_grid(peng_spec_tune,
                           peng_sex_rec,
                           resamples = penguins_cv,
                           grid = k_grid,
                           metrics = metric_set(accuracy))


autoplot(peng_sex_tune)
```


Now having estimated the perfomance of our model on the test set for a variety of values for $k$, we can select the one with the best performance and refit on the full training set. 

```{r}
final_peng_sex <- finalize_model(peng_spec_tune, select_best(peng_sex_tune, "accuracy"))

final_fit_sex <- fit(final_peng_sex, sex ~ flipper_length_mm + body_mass_g + species, penguins_train)
```


```{r}
final_fit_sex %>%
  predict(penguins_test) %>%
  cbind(penguins_test) %>%
  conf_mat(sex,.pred_class)
```



```{r}
final_fit_sex %>%
  predict(penguins_test) %>%
  cbind(penguins_test) %>%
  accuracy(sex,.pred_class) %>%
  kable()
```


```{r}

final_fit_sex %>%
  predict(penguins_test) %>%
  cbind(penguins_test) %>%
  mutate(prediction = ifelse(sex == .pred_class, "Correct", "Incorrect")) %>%
  ggplot(aes(x = flipper_length_mm, y = body_mass_g, color = prediction)) +
  geom_point() +
  facet_wrap(~species) +
  theme(legend.position = "bottom") +
  scale_color_colorblind() +
  labs(x = "Flipper Length (mm)", y = "Body Mass (g)")

```

### Regression

```{r}
peng_spec_tune <- nearest_neighbor(neighbors = tune()) %>%
  set_engine("kknn") %>%
  set_mode("regression")

peng_mass_tune <- tune_grid(peng_spec_tune,
                           peng_mass_rec,
                           resamples = penguins_cv,
                           grid = k_grid,
                           metrics = metric_set(rmse))


autoplot(peng_mass_tune)
```


```{r}
final_peng_mass <- finalize_model(peng_spec_tune, select_best(peng_mass_tune, "rmse"))

final_fit_mass <- fit(final_peng_mass, body_mass_g ~ flipper_length_mm + sex + species , penguins_train)
```


```{r}
final_fit_mass %>%
  predict(penguins_test) %>%
  cbind(penguins_test) %>%
  rmse(body_mass_g,.pred) %>%
  kable()
```


Let's plot our predicted values against the actual values.

```{r}
final_fit_mass %>%
  predict(penguins_test) %>%
  cbind(penguins_test) %>%
  ggplot(aes(x=body_mass_g, y = .pred)) +
  geom_point(color="darkblue") + 
  geom_abline(linetype="dashed") + 
  labs(x = "Actual Body Mass (g)", y = "Predicted Body Mass (g)")
```

Let's see how the results compare across sex and species.

```{r}
final_fit_mass %>%
  predict(penguins_test) %>%
  cbind(penguins_test) %>%
  ggplot(aes(x=body_mass_g, y = .pred, color=sex)) +
  geom_point() + 
  geom_abline(linetype="dashed") + 
  facet_wrap(~species) +
  scale_color_colorblind() +
  labs(x = "Actual Body Mass (g)", y = "Predicted Body Mass (g)")
```
